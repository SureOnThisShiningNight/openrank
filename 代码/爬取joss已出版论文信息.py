#ä¿®æ”¹ä¹‹åè®ºæ–‡åœ°å€æ˜¯å¯¹çš„äº†

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import json

# 1. é…ç½®æµè§ˆå™¨ï¼ˆå¯ç”¨æ— å¤´æ¨¡å¼+ä¼˜åŒ–èµ„æºï¼‰
chrome_options = Options()
chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
chrome_options.add_experimental_option("prefs", {"profile.managed_default_content_settings.images": 2})  # ç¦ç”¨å›¾ç‰‡
chrome_options.add_argument("--headless=new")  # æ— å¤´æ¨¡å¼ï¼šä¸æ‰“å¼€æµè§ˆå™¨çª—å£ï¼Œæ›´ç¨³å®š
chrome_options.add_argument("--disable-gpu")  # é…åˆæ— å¤´æ¨¡å¼
chrome_options.add_argument("--window-size=1920,1080")  # æ¨¡æ‹Ÿçª—å£å¤§å°ï¼Œé¿å…å…ƒç´ å®šä½å¼‚å¸¸
driver = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()),
    options=chrome_options
)
wait = WebDriverWait(driver, 20)  # å»¶é•¿ç­‰å¾…åˆ°20ç§’ï¼Œé€‚é…æ…¢åŠ è½½

all_papers = []
max_pages = 200   # ç›®æ ‡é¡µæ•°
current_page = 1

try:
    target_url = "https://joss.theoj.org/papers/published"
    driver.get(target_url)
    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "paper-card")))  # ç­‰å¾…åˆ—è¡¨é¡µåŠ è½½å®Œæˆ

    # ========== å¤–å±‚ï¼šç¿»é¡µå¾ªç¯ ==========
    while current_page <= max_pages:
        print(f"\n==================== æ­£åœ¨çˆ¬å–ç¬¬ {current_page} é¡µ ====================")
        
        # æ»šåŠ¨åŠ è½½å½“å‰é¡µæ‰€æœ‰å†…å®¹ï¼ˆç”¨æ˜¾å¼ç­‰å¾…æ›¿ä»£éƒ¨åˆ†sleepï¼‰
        driver.execute_script("window.scrollTo(0, 0);")
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)  # ç¼©çŸ­sleep
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        # è·å–å½“å‰é¡µè®ºæ–‡æ€»æ•°
        paper_cards = driver.find_elements(By.CLASS_NAME, "paper-card")
        current_page_paper_count = len(paper_cards)
        print(f"âœ… ç¬¬ {current_page} é¡µæ‰¾åˆ° {current_page_paper_count} ç¯‡è®ºæ–‡ï¼Œçˆ¬å–å…¨éƒ¨{min(20, current_page_paper_count)}ç¯‡")

        # ========== å†…å±‚ï¼šçˆ¬å–å½“å‰é¡µæœ€å¤š20ç¯‡ ==========
        for idx in range(min(20 , current_page_paper_count)):
            # ä¿®å¤æ€»åºå·è®¡ç®—
            total_idx = (current_page - 1) * 20 + (idx + 1)
            print(f"\n=== æ€»ç¬¬ {total_idx} ç¯‡ï¼ˆç¬¬{current_page}é¡µç¬¬{idx+1}ç¯‡ï¼‰===")
            
            # é‡æ–°å®šä½cardï¼Œé¿å…å…ƒç´ å¤±æ•ˆ
            driver.execute_script("window.scrollTo(0, 0);")
            current_cards = driver.find_elements(By.CLASS_NAME, "paper-card")
            if idx >= len(current_cards):
                print("âŒ å½“å‰cardä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            card = current_cards[idx]

            # ç‚¹å‡»è¿›å…¥è¯¦æƒ…é¡µ
            try:
                click_elem = card.find_element(By.CLASS_NAME, "paper-title").find_element(By.TAG_NAME, "a")
                driver.execute_script("arguments[0].scrollIntoView({block: 'top'});", click_elem)
                driver.execute_script("arguments[0].click();", click_elem)
                print("âœ… è·³è½¬åˆ°è¯¦æƒ…é¡µ")
                # ç­‰å¾…è¯¦æƒ…é¡µæ ‡é¢˜åŠ è½½ï¼ˆæ›¿ä»£å›ºå®šsleepï¼‰
                wait.until(EC.presence_of_element_located((By.TAG_NAME, "h1")))

                # ========== æå–æ•°æ® ==========
                detail_title = "æ— æ ‡é¢˜"
                github_link = "æ— githubé“¾æ¥"
                submit_time = "æ— ä¸Šä¼ æ—¶é—´"
                published_time = "æ— å‘è¡¨æ—¶é—´"
                time.sleep(2)  # å¼ºåˆ¶ç­‰å¾…2ç§’ï¼Œç»™JavaScriptè¶³å¤Ÿçš„æ—¶é—´å»æ›´æ–°URL
                paper_link = driver.current_url.strip()  # è¯¦æƒ…é¡µURLå³è®ºæ–‡åœ°å€
                paper_tags = ["æ— è®ºæ–‡æ ‡ç­¾"]
                # ä¿®å¤åˆå§‹ç±»å‹ä¸ºåˆ—è¡¨
                language_of_paper = ["æ— è®ºæ–‡è¯­è¨€"]

                # æå–æ ‡é¢˜
                try:
                    detail_title = driver.find_element(By.TAG_NAME, "h1").text.strip()
                    print(f"âœ… æ ‡é¢˜æå–æˆåŠŸï¼š{detail_title[:50]}...")
                except Exception as e:
                    print(f"âŒ æ ‡é¢˜æå–å¤±è´¥ï¼š{str(e)[:80]}")

                # æå–githubé“¾æ¥
                try:
                    github_link_elem = wait.until(EC.presence_of_element_located(
                        (By.XPATH, "//div[@class='btn-group-vertical']/a[@class='btn paper-btn']")
                    ))
                    github_link = github_link_elem.get_attribute("href").strip()
                    print(f"âœ… githubé“¾æ¥ï¼š{github_link}")
                except Exception as e:
                    print(f"âŒ githubé“¾æ¥æå–å¤±è´¥ï¼š{str(e)[:80]}")

                # æå–ä¸Šä¼ æ—¶é—´
                try:
                    time1_elem = wait.until(EC.presence_of_element_located(
                        (By.XPATH, "//span[@class='small' and contains(text(), 'Submitted')]")
                    ))
                    submit_time = time1_elem.text.strip().replace("Submitted ", "")
                    print(f"âœ… ä¸Šä¼ æ—¶é—´ï¼š{submit_time}")
                except Exception as e:
                    print(f"âŒ ä¸Šä¼ æ—¶é—´æå–å¤±è´¥ï¼š{str(e)[:80]}")

                # æå–å‘è¡¨æ—¶é—´
                try:
                    time2_elem = wait.until(EC.presence_of_element_located(
                        (By.XPATH, "//span[contains(@class, 'small') and contains(text(), 'Published')]")
                    ))
                    published_time = time2_elem.text.strip().replace("Published ", "")
                    print(f"âœ… å‘è¡¨æ—¶é—´ï¼š{published_time}")
                except Exception as e:
                    print(f"âŒ å‘è¡¨æ—¶é—´æå–å¤±è´¥ï¼š{str(e)[:80]}")

                # æå–è®ºæ–‡æ ‡ç­¾
                try:
                    paper_tag_elems = wait.until(EC.presence_of_all_elements_located(
                        (By.XPATH, "//span[@class='badge-lang']/a")
                    ))
                    paper_tags = [elem.text.strip() for elem in paper_tag_elems if elem.text.strip()]
                    print(f"âœ… è®ºæ–‡æ ‡ç­¾ï¼š{paper_tags}")
                except Exception as e:
                    print(f"âŒ æ ‡ç­¾æå–å¤±è´¥ï¼š{str(e)[:80]}")

                # æå–è®ºæ–‡è¯­è¨€
                try:
                    language_elems = wait.until(EC.presence_of_all_elements_located(
                        (By.XPATH, "//div[@class='paper-meta']/h1/following-sibling::span[@class='badge-lang']/a")
                    ))
                    language_of_paper = [a.text.strip() for a in language_elems if a.text.strip()]
                    print(f"âœ… è®ºæ–‡è¯­è¨€ï¼š{language_of_paper}")
                except Exception as e:
                    print(f"âŒ è®ºæ–‡è¯­è¨€æå–å¤±è´¥ï¼š{str(e)[:100]}")

                # ä¿å­˜æ•°æ®
                all_papers.append({
                    "æ€»åºå·": total_idx,
                    "é¡µç ": current_page,
                    "é¡µå†…åºå·": idx+1,
                    "æ ‡é¢˜": detail_title,
                    "githubé“¾æ¥": github_link,
                    "ä¸Šä¼ æ—¶é—´": submit_time,
                    "å‘è¡¨æ—¶é—´": published_time,
                    "è®ºæ–‡åœ°å€": paper_link,
                    "è®ºæ–‡æ ‡ç­¾": paper_tags,
                    "è®ºæ–‡è¯­è¨€": language_of_paper
                })

                # è¿”å›åˆ—è¡¨é¡µ
                driver.back()
                # ç­‰å¾…åˆ—è¡¨é¡µåŠ è½½å®Œæˆ
                wait.until(EC.presence_of_element_located((By.CLASS_NAME, "paper-card")))

            except Exception as e:
                print(f"âŒ å•ç¯‡è®ºæ–‡æå–å¤±è´¥ï¼š{str(e)[:100]}")
                driver.back()
                time.sleep(1)
                continue

        # ========== ç¿»é¡µé€»è¾‘ ==========
        if current_page < max_pages:
            try:
                print(f"\nğŸ” å‡†å¤‡ç¿»åˆ°ç¬¬ {current_page+1} é¡µ...")
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                # ç­‰å¾…NextæŒ‰é’®å¯ç‚¹å‡»
                next_btn = wait.until(EC.element_to_be_clickable(
                    (By.XPATH, "//div[@class='pagination']/a[contains(@aria-label, 'next')]")
                ))
                driver.execute_script("arguments[0].click();", next_btn)
                # ç­‰å¾…ä¸‹ä¸€é¡µåŠ è½½
                wait.until(EC.presence_of_element_located((By.CLASS_NAME, "paper-card")))
                current_page += 1
                print(f"âœ… æˆåŠŸç¿»åˆ°ç¬¬ {current_page} é¡µ")
            except Exception as e:
                print(f"âŒ ç¿»é¡µå¤±è´¥ï¼ˆå¯èƒ½å·²åˆ°æœ€åä¸€é¡µï¼‰ï¼š{str(e)[:80]}")
                break
        else:
            print(f"\nâœ… å·²çˆ¬å®ŒæŒ‡å®šçš„ {max_pages} é¡µ")
            break

# ========== ä¿å­˜æ•°æ®ï¼ˆè¾¹çˆ¬è¾¹ä¿å­˜ï¼Œé¿å…ä¸¢å¤±ï¼‰ ==========
finally:
    if all_papers:
        # ä¿å­˜JSONLï¼ˆæ¨èåç»­å¤„ç†ï¼‰
        with open("è®ºæ–‡è¯¦æƒ…_æ‰¹é‡çˆ¬å–.jsonl", "w", encoding="utf-8") as f_json:
            for paper in all_papers:
                json.dump(paper, f_json, ensure_ascii=False)
                f_json.write("\n")
        
        # # ä¿å­˜TXT
        # with open("è®ºæ–‡è¯¦æƒ…_æ‰¹é‡çˆ¬å–.txt", "w", encoding="utf-8") as f_txt:
        #     for p in all_papers:
        #         f_txt.write("="*50 + "\n")
        #         f_txt.write(f"æ€»åºå·ï¼š{p['æ€»åºå·']}\n")
        #         f_txt.write(f"é¡µç ï¼š{p['é¡µç ']} | é¡µå†…åºå·ï¼š{p['é¡µå†…åºå·']}\n")
        #         f_txt.write(f"æ ‡é¢˜ï¼š{p['æ ‡é¢˜']}\n")
        #         f_txt.write(f"githubé“¾æ¥ï¼š{p['githubé“¾æ¥']}\n")
        #         f_txt.write(f"ä¸Šä¼ æ—¶é—´ï¼š{p['ä¸Šä¼ æ—¶é—´']}\n")
        #         f_txt.write(f"å‘è¡¨æ—¶é—´ï¼š{p['å‘è¡¨æ—¶é—´']}\n")
        #         f_txt.write(f"è®ºæ–‡åœ°å€ï¼š{p['è®ºæ–‡åœ°å€']}\n")
        #         f_txt.write(f"è®ºæ–‡æ ‡ç­¾ï¼š{','.join(p['è®ºæ–‡æ ‡ç­¾'])}\n")
        #         f_txt.write(f"è®ºæ–‡è¯­è¨€ï¼š{','.join(p['è®ºæ–‡è¯­è¨€'])}\n")
        #         f_txt.write("="*50 + "\n\n")
        
        print(f"\nâœ… æ•°æ®ä¿å­˜å®Œæˆï¼å…±çˆ¬å– {len(all_papers)} ç¯‡è®ºæ–‡")
    else:
        print("\nâŒ æœªçˆ¬å–åˆ°ä»»ä½•è®ºæ–‡æ•°æ®")
    
    driver.quit()
    print("\nğŸ”š ç¨‹åºç»“æŸ")